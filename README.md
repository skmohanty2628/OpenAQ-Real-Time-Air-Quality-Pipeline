# ğŸŒ OpenAQ Real-Time Air Quality Pipeline
### End-to-End ETL Pipeline using OpenAQ API, Databricks, Delta Lake & PySpark

![Badge](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python)
![Badge](https://img.shields.io/badge/Databricks-Spark-red?logo=databricks)
![Badge](https://img.shields.io/badge/Apache_Spark-ETL-orange?logo=apachespark)
![Badge](https://img.shields.io/badge/Delta_Lake-ACID-green?logo=deltalake)
![Badge](https://img.shields.io/badge/MinIO-Object_Storage-yellow?logo=minio)
![Badge](https://img.shields.io/badge/ETL-Pipeline-blueviolet)
![Badge](https://img.shields.io/badge/Status-Production_Ready-brightgreen)


This project implements a complete real-time Air Quality Data Engineering pipeline built with:

- OpenAQ API (global real-time air-quality data)
- Databricks (Spark, Delta Lake, notebooks, SQL)
- PySpark (ETL transformations)
- MinIO (S3 object storage)
- GitHub (version control & documentation)

It covers: Ingestion â†’ Bronze â†’ Silver â†’ Gold â†’ Analytics â†’ Version Control

---

# ğŸ—ï¸ Architecture Overview

OpenAQ API â†’ MinIO (Raw Storage) â†’ Bronze (Raw Delta Table)
          â†’ Silver (Cleaned & Standardized Table)
          â†’ Gold (Aggregated Analytics)
          â†’ Spark SQL & BI Dashboards

---

# ğŸ“¦ Project Structure

OpenAQ-Real-Time-Air-Quality-Pipeline/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ AirQuality_Pipeline.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion_openaq.py
â”‚   â”œâ”€â”€ upload_to_minio.py
â”‚   â”œâ”€â”€ silver_cleaning.py
â”‚   â””â”€â”€ gold_aggregations.py
â”œâ”€â”€ exports/
â”‚   â”œâ”€â”€ pipeline.html
â”‚   â”œâ”€â”€ pipeline.pdf
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ sample_raw.json
â””â”€â”€ README.md

---

# ğŸ¥‡ Bronze Layer â€“ Raw Ingestion

â€¢ Fetches full global dataset with pagination  
â€¢ JSON stored in MinIO: air-quality-raw/YYYY/MM/DD/  
â€¢ In-memory upload using BytesIO  
â€¢ Delta Bronze table created in Databricks  

---

# ğŸ¥ˆ Silver Layer â€“ Cleaned & Standardized

â€¢ Flatten nested JSON structures  
â€¢ Remove arrays: licenses, instruments, sensors  
â€¢ Standardize strings: UPPER(), TRIM()  
â€¢ Remove rows missing critical fields (id, lat, lon, country_name)  
â€¢ Drop columns where all values are NULL  

Output Table:
air_quality_silver_locations

---

# ğŸ¥‡ Gold Layer â€“ Aggregated Analytics

Country-Level Metrics:
â€¢ Total stations  
â€¢ Average latitude, longitude  
â€¢ Station distribution  

Saved as:
air_quality_gold_country_stats

---

# ğŸ“Š SQL & PySpark Analytics Examples

SQL Filtering:
SELECT * FROM air_quality_silver_locations WHERE country_name = 'INDIA';

SQL Aggregation:
SELECT country_name, COUNT(*) FROM air_quality_silver_locations GROUP BY country_name;

PySpark Filter:
df_silver.filter(df_silver.country_name == "UNITED STATES").show();

---

# ğŸ—‚ï¸ Data Storage (Delta Lake)

â€¢ Bronze: air_quality_bronze  
â€¢ Silver: air_quality_silver_locations  
â€¢ Gold: air_quality_gold_country_stats  

---

# ğŸš€ Future Enhancements

â€¢ Schedule pipeline (every 5 hrs)  
â€¢ ML forecasting  
â€¢ Real-time streaming  
â€¢ BI dashboards  

---

# ğŸ‘¤ Author
**Subham Mohanty**  
GitHub: https://github.com/skmohanty2628
